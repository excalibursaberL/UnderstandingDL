{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 25\n",
    "SPLIT_RATIO = 0.8\n",
    "\n",
    "# 检查设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"当前使用设备: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU 型号: {torch.cuda.get_device_name(0)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "数据准备",
   "id": "1de539b7d3e5f59b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "full_train_dataset = datasets.FashionMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "train_dataset = datasets.FashionMNIST(root='../data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.FashionMNIST(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "train_size = int(SPLIT_RATIO * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "print(f\"正在划分数据集 (8:2)...\")\n",
    "print(f\"训练集数量: {train_size}\")\n",
    "print(f\"验证集数量: {val_size}\")\n",
    "\n",
    "# 3. 随机划分\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42) # 设置随机种子，保证每次划分一致\n",
    ")\n",
    "\n",
    "# 4. 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n"
   ],
   "id": "8984df81d85ceada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型定义",
   "id": "134ca46fc70b743e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "            nn.Linear(120, 84), nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = LeNet().to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "model.apply(init_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ],
   "id": "8b5f57f44eccd65b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "训练",
   "id": "ccb131377382fd8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(f\"开始训练 {EPOCHS} 轮...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- 训练阶段 ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 内层进度条：显示当前 Epoch 的 Batch 进度\n",
    "    # 使用 tqdm 包装 train_loader\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\", leave=False)\n",
    "\n",
    "    for X, y in train_bar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # 实时更新进度条后缀，显示当前 batch 的 loss\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "\n",
    "    # --- 验证阶段 ---\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 验证阶段通常很快，一般不需要复杂的进度条，但为了统一也可以加上\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            val_running_loss += loss.item() * X.size(0)\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "    epoch_val_loss = val_running_loss / len(val_dataset)\n",
    "    epoch_val_acc = correct / total\n",
    "\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "    # 每一轮结束后打印汇总信息 (tqdm 会自动处理换行)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f} - \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f} - \"\n",
    "          f\"Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"训练结束。总耗时: {total_time:.2f} 秒\")"
   ],
   "id": "e65fccd7cb92c4a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "绘制结果",
   "id": "7b47d2f9a9b1ea08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_acc'], label='Val Accuracy', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "6156eb2dd8c675a2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
